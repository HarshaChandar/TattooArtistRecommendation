{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "import matplotlib.pyplot as plt\n",
    "from lshash import LSHash\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Ensure tatrec package is in the path\n",
    "sys.path.append(os.path.join(Path.cwd(), \"..\", \"tatrec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tatrec.notebook_funcs import get_data_from_folder, print_data_classes_size, plot_similar_tats\n",
    "from tatrec.config import path_models, path_train_chicago, path_train_cnn, path_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128   # batch size\n",
    "arch = models.resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same dataset used to train the model originally\n",
    "data = get_data_from_folder(path_train_cnn, bs, 64, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, arch, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(path_models / \"tatrec-stage-2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_from_folder(path_train_chicago, bs, 64, tfms)\n",
    "learn.data = data\n",
    "learn.purge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data_classes_size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show sample data\n",
    "data.show_batch(rows=4, figsize=(10,9), hide_axis=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a hook right after convolutional part of resnet 50 and max pooling layer which generates a 4096 length vector for a particular image of 256*256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a hook (used for saving intermediate computations)\n",
    "# used to extract before the last FC layer for use in similarity matching\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): \n",
    "        self.hook = m.register_forward_hook(self.hook_fn)\n",
    "        self.features = None\n",
    "    def hook_fn(self, module, input, output): \n",
    "        out = output.detach().cpu().numpy()\n",
    "        if isinstance(self.features, type(None)):\n",
    "            self.features = out\n",
    "        else:\n",
    "            self.features = np.row_stack((self.features, out))\n",
    "    def remove(self): \n",
    "        self.hook.remove()\n",
    "        \n",
    "sf = SaveFeatures(learn.model[1][5]) ## Output before the last FC layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By running this feature vectors would be saved in sf variable initated above\n",
    "preds = learn.get_preds(data.train_ds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the percentage of tattoos that are recognized as not a tattoo\n",
    "print((1 - len(np.where(preds[:,1] < 0.5)))/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting in a dictionary of {img_path:featurevector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = [str(x) for x in (list(data.train_ds.items))]\n",
    "feature_dict = dict(zip(img_path,sf.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting as pickle\n",
    "pickle.dump(feature_dict, open(path_data_clean/\"feature_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Locality Sensitive hashing to find near similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Feature dictionary\n",
    "feature_dict = pickle.load(open(path_data_clean/\"feature_dict.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Locality Sensitive Hashing\n",
    "# params\n",
    "k = 30 # hash size\n",
    "L = 5  # number of tables\n",
    "d = 512 # Dimension of Feature vector\n",
    "lsh = LSHash(hash_size=k, input_dim=d, num_hashtables=L)\n",
    "\n",
    "# LSH on all the images\n",
    "for img_path, vec in tqdm_notebook(feature_dict.items()):\n",
    "    lsh.index(vec.flatten(), extra_data=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting as pickle\n",
    "pickle.dump(lsh, open(path_models/'lsh.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Feature and lsh dictionaries\n",
    "feature_dict = pickle.load(open(path_data_clean/'feature_dict.pkl','rb'))\n",
    "lsh = pickle.load(open(path_models/'lsh.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_item = 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similar_tats(extract_item, feature_dict, lsh, 5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
